---
title: 'Provenance of Training without Training Data: Towards Privacy-Preserving DNN
  Model Ownership Verification'
authors:
- Yunpeng Liu
- Kexin Li
- liuzhuotao
- Bihan Wen
- Ke Xu
- Weiqiang Wang
- Wenbiao Zhao
- Qi Li
doi: https://dl.acm.org/doi/abs/10.1145/3543507.3583198
seq: 1
conference_url: https://www2023.thewebconf.org/
abstract: In the era of deep learning, it is critical to protect the intellectual
  property of high-performance deep neural network (DNN) models. Existing proposals,
  however, are subject to adversarial ownership forgery (e.g., methods based on watermarks
  or fingerprints) or require full access to the original training dataset for ownership
  verification (e.g., methods requiring the replay of the learning process). In this
  paper, we propose a novel Provenance of Training (PoT) scheme, the first empirical
  study towards verifying DNN model ownership without accessing any original dataset
  while being robust against existing attacks. At its core, PoT relies on a coherent
  model chain built from the intermediate checkpoints saved during model training
  to serve as the ownership certificate. Through an in-depth analysis of model training,
  we propose six key properties that a legitimate model chain shall naturally hold.
  In contrast, it is difficult for the adversary to forge a model chain that satisfies
  these properties simultaneously without performing actual training. We systematically
  analyze PoT’s robustness against various possible attacks, including the adaptive
  attacks that are designed given the full knowledge of PoT’s design, and further
  perform extensive empirical experiments to demonstrate our security analysis.
tag: WWW 23
date: '2023-01-01T00:00:00Z'
publication: International World Wide Web Conference (WWW) 2023
publication_short: WWW23
Subtype: AI Security
---
